---
title: 面试问题汇总
tags: Java面试题
---

## Redis

* ### 你在项目中的哪些场景下用到了Redis呢？

　　我在项目中主要使用Redis实现了缓存和生成唯一序列的功能。在公积金项目中，我们使用Redis缓存了一些热点数据，主要是企业的一些基本信息，还使用Redis来临时存储用户登录时的验证码；在OCIF项目中，我们使用Redis缓存了外部接口中的一些数据，主要是银行管户经理的一些信息，我们还使用Redis为客户生成了自增的唯一id，用到了incr命令。

* ### 什么是缓存穿透？怎么解决？

　　缓存穿透指的是要查询的数据在数据库、Redis中都不存在，导致缓存无法建立，用户频繁地请求数据库，给数据库造成压力。

　　解决办法是：

　　1、为不存在的数据建立空缓存。这种方法是缺点是占用内存，而且容易造成缓存与数据库不一致，解决办法是为空缓存设置过期时间；

　　2、在客户端和Redis之间加入一个布隆过滤器，用户请求先到达布隆过滤器，如果数据不存在，就直接拒绝该请求。

* ### 什么是缓存击穿？怎么解决？

　　缓存击穿指的是缓存中的某个key突然过期，恰好有大量并发请求来查询这个key，导致大量请求访问数据库，给数据库造成压力。

　　解决办法是：

　　1、使用互斥锁，保证当缓存过期后，只能有一个线程可以重建缓存，重建的过程中其它线程都不能访问数据库；

　　2、为当前key设置逻辑过期时间，当缓存逻辑过期后，为所有请求返回缓存中过期的值，然后用一个独立线程去重建缓存，更新逻辑过期时间。

　　如果要保证数据库和缓存的一致性，推荐使用互斥锁；如果要保证高可用性，推荐使用逻辑过期。

* ### 什么是缓存雪崩？怎么解决？

　　缓存雪崩指的是缓存中大量key同时过期，导致大量请求同时访问数据库，给数据库造成压力。

　　解决办法是：

　　1、给这些key设置随机过期时间，避免同时过期；

　　2、为key设置逻辑过期时间。

* ### 如何保证数据库和缓存的一致性？

　　在公积金项目中，我们使用Redis缓存了企业的一些基本信息，对数据的一致性要求不是很高，于是我们采用了缓存主动更新+超时剔除的策略，缓存主动更新指的是在更新企业信息后删除缓存，之所以要先更新后删除，是因为更新操作往往更耗时，这样可以减少脏数据的产生，超时剔除指的是为缓存设置过期时间作为兜底，时间为24小时。

　　在OCIF项目中，有一些数据需要去请求外部接口，比如银行管户经理的一些信息，这部分数据我们无法去更新，并且更新频率并不高，所以我们为这些缓存设置了30分钟的过期时间。

* ### Redis是怎样实现数据持久化的？

　　Redis实现数据持久化的方式有两种：RDB和AOF。

　　RDB指的是把某一时刻的Redis进程中的数据生成快照保存到磁盘。恢复数据时也是从快照文件中恢复。它可以手动触发，也可以自动触发，手动触发有两个命令`save`和`bgsave`，前者会占用主线程，后者会新开一个线程，自动触发需要在`redis.conf`中进行配置，即在指定时间内进行了多少次修改就会触发持久化。

　　AOF指的是把所有写命令保存到磁盘，恢复数据时会把所有写命令执行一遍。AOF默认是关闭的，需要在`redis.conf`中手动开启。它的自动触发策略有三种，分别是每执行一条写命令就触发、每隔一秒就触发、由操作系统决定何时触发，一般选择每隔一秒就触发的策略。可以使用重写命令对`aof`文件进行瘦身。

　　RDB和AOF的区别是，RDB备份数据的速度慢，但是恢复数据的速度快，而AOF备份数据的速度快，但是恢复数据的速度慢。并且由于RDB的备份速度慢，所以丢失数据的概率更高。

* ### Redis的数据过期策略有哪些？

　　Redis提供了两种数据过期策略，分别是惰性删除和定期删除。惰性删除指的是当查询该key时才去检查是否过期，如果过期就删除。定期删除指的是每隔一段时间就对key进行过期检查，然后删除过期的key。

　　Redis的数据过期策略是惰性删除和定期删除配合使用。

* ### Redis的内存淘汰策略有哪些？

　　Redis提供了8种内存淘汰策略，默认的策略是不删除任何数据，当内存不足时直接报错。还有两个比较重要的策略是LRU和LFU，LRU(Least Recently Used)即最近最少使用，当内存不足时，Redis会删除最后一次访问时间最早的key。LFU(Least Least Frequently Used)即最少频率使用，当内存不足时，Redis会删除访问频率最低的key。

　　我们的项目中使用的都是`allkeys-lru`，即删除访问频率最低的数据。

* ### 数据库中有1000万数据，Redis只能存放20万数据，如何保证Redis中的数据都是热点数据？

　　可以使用`allkeys-lru`的内存淘汰策略，只保存使用频率最高的数据。

* ### Redis内存用完了会发生什么？

　　这个要看Redis的内存淘汰策略是怎么配置的，如果是默认配置，Redis在内存用完后会直接报错。我们使用的是`allkeys-lru`策略，内存不足时会删除使用频率最低的数据。

* ### Redis有哪些集群方案？

　　Redis有三种集群方案：主从复制、哨兵模式、分片集群。

　　主从复制中，主节点负责写入数据，从节点负责读取数据。主从节点同步数据的流程是，第一次同步采用全量复制的方式进行同步，之后采用增量复制的方式进行同步。

　　哨兵模式中，哨兵集群会对Redis的主从节点进行监控，当主节点宕机后进行自动故障恢复，并通知客户端。

* ### 你们的Redis是单节点还是集群？

　　我们的Redis使用的是1主1从+哨兵集群，单个节点不超过10G内存。

* ### Redis为什么这么快？

　　1、Redis是基于内存的数据库；

　　2、Redis使用单线程操作数据，避免了线程上下文切换带来的损耗。

　　3、使用了IO多路复用模型，可以处理更多网络请求。

* ### Redis有哪些数据类型？

　　Redis有五种常用的数据类型，分别是`string、list、hash、set、zset`。它们的常用命令分别有：`set/get`、`lpush/lpop`、`hmset/hmget`、`sadd/smembers`、`zadd/zrange`等。

## MySQL

* ### 你是怎样定位慢查询的？

　　如果某个页面加载比较慢，我就会定位到页面涉及到的SQL，然后在数据库中进行分析和优化。

　　对于MySQL数据库，可以使用慢查询日志来定位查询速度慢的SQL。

* ### 如果一条SQL执行很慢，如何进行分析？

　　1、查看explain执行计划；

　　2、通过type查看是否是全表扫描；

　　3、通过key和key_len判断是否命中了索引，索引有没有失效；

　　4、通过extra查看其它信息，比如是否回表查询。

* ### 什么是索引？

　　索引是帮助数据库高效查询数据的数据结构。

* ### 索引的底层数据结构是什么？

　　MySQL的InnoDB引擎、Oracle数据库中索引的数据结构都是B+树。B+树的特点是：1、树的高度很低；2、非叶子结点只存放指针，叶子结点存放指针和数据；3、叶子结点是有序的双向链表。

* ### B树和B+树的区别是什么？

　　B树的非叶子结点存放了指针和数据，而B+树的非叶子结点只存放了指针，因此B+树比B树的高度更低，查询数据时磁盘IO的次数更少。并且由于B+树的叶子结点存放了所有的数据，而且是有序的，因此它的排序和范围查询效率更高。

* ### 什么是聚集索引和非聚集索引？什么是回表？

　　聚集索引指的是索引树的叶子结点存放的是行数据，非聚集索引指的是索引树的叶子结点存放的是对应的主键，回表指的是先通过非聚集索引查询出主键，然后再用主键通过聚集索引查询出行数据。

　　对于一张表，聚集索引有且只有一个，非聚集索引可以有多个。

* ### 什么是覆盖索引？

　　覆盖索引指的是要查询的数据在索引列中已经存在，不需要回表查询。

* ### 怎样提高深度分页查询的效率？

　　覆盖索引+子查询。先在子查询中查出分页范围内的覆盖索引，然后查询出这些索引对应的行数据。这样可以避免很多无效的回表查询。

* ### 创建索引的原则有哪些？

　　创建索引的原则很多，比如：

　　1、对数据量比较大(大于10万条)的表创建索引；

　　2、对查询、排序、分组频率比较高的字段创建索引；

　　3、尽量创建联合索引，因为可以更好地使用覆盖索引，联合索引中把区分度较高的字段放在前面；

　　4、要控制索引的数量，一般不超过5个。

* ### 索引失效的场景有哪些？

　　1、违反最左前缀匹配规则，用联合索引查询中，查询条件中缺少索引中的某个字段，会导致该字段后面的索引失效；

　　2、在索引列上使用了函数运算，导致索引失效；

　　3、使用or作为查询条件时，必须保证两边的字段都有索引，否则索引会失效；

　　4、当数据库评估走索引不如全表扫描效率高时，索引也会失效。

* ### SQL优化的方式有哪些？

　　SQL优化的方式主要包括：主键优化、索引优化、JOIN连接优化。

　　1、主键优化，在插入数据时，尽量按照主键顺序进行插入；

　　2、索引优化，尽量通过索引进行查询、分组、排序，尽量使用覆盖索引，同时要避免索引失效；

　　3、JOIN连接优化，尽量让小表驱动大表。

* ### 事务的特性是什么？

　　事务的特性是ACID，分别指的是原子性、一致性、隔离性、持久性。举个例子，A向B转账100块钱，转账成功后A的账户减去100元，B的账户增加100元，原子性指的是A和B账户的变动要么都成功、要么都失败，一致性指的是转账时数据要一致，A减去100，B就要加100，隔离性指的是A和B之间转账不能被其它事务干扰，持久性指的是事务提交后持久化到磁盘。

* ### 并发事务带来哪些问题？

　　并发事务带来的问题有脏读、不可重复读、幻读。

　　脏读指的是一个事务在执行过程中，读取到了另一个事务还没有提交的数据。

　　不可重复读指的是一个事务在执行过程中，另一个事务对数据进行了修改并提交，导致第一个事务中两次读取的数据可能不一致。

　　幻读指的是一个事务在执行过程中，另一个事务新插入了一条数据，但是在第一个事务中查询不到这条数据，但是却可以更新，就像出现了幻觉。

* ### 怎么解决这些问题？

　　MySQL提供了四种隔离级别，分别是读未提交、读已提交、可重复读、串行化。

　　读未提交是最低的隔离级别，可能会出现脏读、不可重复读、幻读问题。

　　读已提交是Oracle默认的隔离级别，避免了脏读，但可能出现不可重复读、幻读。

　　可重复读是MySQL默认的隔离级别，避免了脏读、不可重复读，但是可能出现幻读。

　　串行化是最高的隔离级别，避免了脏读、不可重复读、幻读，但是并发效率太低。

## Spring

* ### 什么是AOP？

　　AOP指的是面向切面编程，就是把系统中的公共代码抽取出来，动态地织入到业务逻辑中，实现公共代码和业务代码的分离，降低了系统的耦合度，减少了代码数量。

* ### 你们系统中有没有用到AOP？

　　我们项目中的用户管理模块都使用了AOP日志来记录用户的操作日志。具体做法就是使用AOP的环绕通知和切点表达式，配合自定义注解，在用户操作的业务逻辑之前记录用户的一些信息，保存到数据库。此外，Spring的数据库事务也使用了AOP。

* ### Spring事务失效的场景有哪些？

　　1、如果在事务方法中手动捕获了异常，但是没有抛出异常，就会导致事务失效。

　　2、事务方法默认只能回滚RuntimeException，所以最好在注解中声明要回滚的异常(`rollbackFor`)。

　　3、事务方法必须是public方法。

* ### SpringMVC的执行流程是什么？

　　1、SpringMVC的核心是`DispatcherServlet`，请求会先到达这个类，然后在它的init方法中创建Spring容器和对象；

　　2、如果配置了过滤器，那么请求会到达过滤器，然后再到达`DispatcherServlet`的service方法；

　　3、在service方法中，会根据请求参数寻找目标Controller和方法，并执行拦截器的方法，然后会给目标方法绑定参数，执行目标方法，获得结果；

　　4、再次执行拦截器的方法，并将结果转换为JSON字符串，写入响应；

　　5、最后回到过滤器，将响应发送给客户端。

* ### SpringBoot自动配置的原理是什么？

　　1、Spring将企业开发的各种场景都抽取出来，做成一个个启动器，启动器整合了某个场景下所需的所有依赖，并提供了默认配置，只要在maven依赖中引入启动器，就可以实现自动配置；

　　2、启动器中有一个`spring.factories`配置文件，这个文件中有一个key名为`EnableAutoConfiguration`的属性，属性值是一些自动配置类，自动配置类中会根据情况使用不同的配置；

　　3、SpringBoot的启动类注解中有个`EnableAutoConfiguration`注解，它负责导入`spring.factories`配置文件中的所有配置类。

* ### Spring有哪些常用注解？

　　1、Spring核心框架的注解有：`@Component、@Service、@Controller、@Repostority、@Scope`（实例化相关）、`@Autowired、@Qualifier`（注入相关）、`@ComponnetScan、@Configuration、@Bean`（配置类相关）。

　　`@EnableAspectAutoProxy、@Before、@Transactional`（AOP相关）。

　　2、SpringMVC的注解有：`@RequestMapping、@RequestParam、@RequestBody、@Responsbody、@RestController`。

　　3、SpringBoot的注解有：`@SpringbootApplication、@EnableAutoConfiguration`。

## MyBatis

* ### MyBatis的执行流程是什么？

　　MyBatis是对JDBC的封装。它的执行流程是：

　　1、创建SqlSessionFactory对象；

　　2、创建SqlSession对象；

　　3、通过SqlSession对象获取Mapper代理对象；

　　4、通过Mapper代理对象操作数据库；

　　5、通过SqlSession对象提交事务。

* ### MyBatis支持延迟加载吗？

　　支持，MyBatis延迟加载默认关闭，可以在配置文件中设置`lazyLoadingEnabled=true`来开启。

　　延迟加载指的是进行关联查询时，只查询主对象的属性，只有当访问具体属性时，才会去查询关联对象的属性。

　　延迟加载的原理是CGLIB动态代理。

* ### MyBatis的缓存用过吗？

　　用过。

　　一级缓存默认开启，作用范围是SqlSession，本质上是一个Map，key是Sql相关的hash值，value是查询结果。

　　二级缓存默认关闭，可以通过`</cache>`标签开启，也可以在sql标签中添加`useCache=true`单独开启。二级缓存作用域是nameSpace。底层数据结构和一级缓存类似。

　　一级缓存和二级缓存都会在增删改后被清空，二级缓存可以在sql标签中使用`flushCache=true`单独进行配置。

## Kafka

* ### Kafka如何保证消息不丢失？

　　从生产者到broker，再到消费者的过程中都可能会丢失消息。

　　1、从生产者到topic：发送消息时传入一个回调函数，当消息发送失败时回调函数可以捕获到异常，然后我们就可以重新发送消息或者记录日志。同时在生产者中还可以设置消息重试，如果因为网络抖动导致消息发送失败，就可以使用重试机制解决。

　　2、broker：broker是通过消息确认机制保证消息不丢失的，acks=0代表生产者不会等待broker的确认信号，acks=1(默认值)代表生产者只会等待broker主节点的确认信号，acks=all代表生产者需要等待所有节点的确认信号。

　　3、broker到消费者：可以禁用自动提交偏移量，改为手动提交偏移量。

* ### Kafka如何保证不重复消费？

　　可以在数据库中增加消息记录表，消费时先去表里面查询，如果可以查到，说明是重复数据，不再消费。这样就保证了幂等性。

* ### Kafka如何保证顺序消费？

　　为所有消息指定相同的key，这样消息会进入同一个分区，这个分区内的消息就是有序的。

## 设计模式

* ### 你在项目中使用了哪些设计模式？

　　在公积金项目中，有一个功能是需要解析用户上传的表格文件，表格文件有xls和xlsx等多种类型，旧代码中是通过if...else判断来区分文件类型的，我对这些代码进行了优化，把不同类型文件的处理流程包装成了不同的策略类，这样以后如果要新增一种文件类型，就不需要修改旧代码了，只需要新增一个策略类即可。

　　在OCIF项目中，我们要对不同类型的客户进行不同的处理，比如只有手机号的客户，它的id应该以7开头，只有unionid的客户，它的id应该以0开头等等，我们使用了工厂方法模式加上策略模式，对代码进行了重构，把不同类型客户的处理流程封装到策略类中，工厂类会根据不同的客户类型返回不同的策略对象，这样就实现了处理方式的解耦。

* ### 单点登录怎么实现？

　　单点登录指的是用户只需要登录一次，就可以访问所有信任的模块。

　　单点登录可以通过Redis+Token实现，具体做法是用户登录成功后，为每个用户生成一个token字符串，然后将token作为key，用户信息作为value存入Redis，同时将Token返回给用户浏览器，浏览器会保存Token，当用户访问其它模块时，会携带浏览器中的Token，先去Redis中查询Token的key是否存在，如果存在，则登录成功，同时将用户信息保存到ThreadLocal中，供其它方法使用，如果不存在，说明Token过期，此时需要再次登录。

* ### 你在线上遇到过什么棘手的问题？是怎么解决的？

　　1、设计模式

　　在开发OCIF项目的时候，因为要对不同类型的客户进行不同的处理，处理规则比较复杂，并且在开发的过程中，由于接入了多个外部渠道，导致处理规则经常发生变化，于是我们就把不同类型客户的处理方式封装到了不同的策略类中，降低了耦合性，同时也降低了代码编写错误的概率。

　　2、SQL优化

　　在OCIF项目中，由于表中数据量比较大，有大概5000万到2亿多条数据，导致很多数据查询比较慢，于是我就对SQL进行了优化，优化的方式包括加索引、尽量用小表去驱动大表、对limit深页查询的优化。经过优化，大大提高了查询速度，有的查询本来耗时十几秒，优化后降低到几百毫秒。

　　3、缓存外部接口

　　由于我们的项目中需要查询外部接口的数据，而外部接口的查询速度比较慢，而且不能经常请求，经常请求会给外部接口造成压力，于是我们就用Redis缓存了这部分数据，也就是银行管户经理的一些信息，提高了查询速度，也减轻了外部接口的压力。由于这部分数据更改的频率并不高，所以我们设置了30分钟的过期时间。

　　4、接口幂等

　　由于我们的系统要通过kafka接收数据，所以就有可能出现消息重复消费或者消费失败的问题。对此我们的解决方案是，我们在处理消息之前，会先去数据库中查询这条消息是否已经存在，如果存在，就不再消费，这就解决了重复消费的问题。同时我们会在一张消息历史记录表中记录所有失败的消息，每天将这些消息导入大数据平台，最后再回到kafka进行重新消费。

　　5、多线程消费

　　在OCIF项目中，因为客户的存量数据比较多，我们最开始用一个分区进行消费，速度很慢，全部数据消费完要花十几天，后来分区增加到4个，同时使用4个线程进行消费，花了三天就消费完了。

* ### 生产环境的问题怎么排查？

　　首先就是通过日志进行排查，如果环境支持，还可以使用远程debug来进行排查。

* ### 怎么快速定位系统的瓶颈？

　　我们主要是上线前对接口进行了压测，使用的工具是jmeter。

## 其它

* ### 你们的项目中是怎么采集日志的？

　　我们的项目使用ELK采集日志，logstash负责收集日志，Es负责存储日志，kibana负责展示日志。

　　除了ELK，还可以手动查看日志文件，具体的命令有：

　　1、`tail -f -n 10 my.log`：实时监控日志文件后10行；

　　2、`cat -n my.log | tail -n +100 | head -n 10`：查看第100行到109行；

　　3、`cat -n my.log | grep debug`：根据关键字查询。

* ### 你们是怎么定位系统瓶颈的？

　　可以使用jmeter压测工具来定位系统瓶颈，具体的指标包括**RT(响应时间)、QPS(每秒查询数量)、并发数、吞吐量**等等。

　　它们之间的关系是：

　　**QPS=并发数/平均响应时间；**

　　吞吐量由RT、QPS、并发数共同决定。

　　我们OCIF系统的消费端并发数量是4，每秒大概能消费1000条数据，查询端的响应时间一般在200-500ms左右。
