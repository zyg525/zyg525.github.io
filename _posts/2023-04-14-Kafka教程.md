---
title: Kafka教程
tags: 消息中间件 Kafka
---

## 一、Kafka简介

　　**Kafka**是由Apache软件基金会开发的一个开源流处理平台，由Scala和Java编写。该项目的目标是为处理实时数据提供一个统一、高吞吐、低延迟的平台。其持久化层本质上是一个“按照分布式事务日志架构的大规模发布/订阅消息队列”，这使它作为企业级基础设施来处理流式数据非常有价值。

　　Kafka的架构图如下所示：

![Kafka架构图](/assets/img/java/kafka架构图.png)

　　Kafka中的几个重要概念：

　　1、**Topic**：Kafka通过Topic对消息进行分类，一个Topic中可以有多个Partition，以此来提高并发性能。同一个Topic中的Partition可以分布在不同的服务器上，即Topic可以跨服务器。

　　2、**Partition**：生产者向一个Topic发送消息时，可以指定一个key，相同key的消息会被发送到相同的Partition中，如果不指定key，消息会以轮询的方式发送到所有Partition中。同一个Partition中的消息是有序的，但不同Partition中的消息是无序的。

　　3、**消费者**：Kafka中一个消费者可以消费多个Partiton，但是每个Partition只能有一个消费者，并且Partition的消费者由Kafka自动分配，不能手动指定。如果消费者数量大于Partition数量，那么多余的消费者就会空闲。

　　4、**消费者组**：消费者组是一组消费者的集合，同一个消费者组订阅的是同一个Topic，组内的消费者分别消费不同的Partition。不同的消费者组也可以订阅同一个Topic，消费者组之间的消费是独立的、互不影响的。

　　5、**Offset**：每次向Partition中写入消息时，都会为这条消息生成一个递增的整数作为偏移量(从0开始)，Kafka可以通过偏移量来追踪消息在Partition中的位置。当Partition中的消息被消费时，会向一个特殊的Topic中发送消息，消息里包含每个Partition的偏移量。当消费者更换Partition时，会根据每个Partition最后一次提交的偏移量，从指定的位置开始消费。

## 二、生产者

* ### 引入依赖

　　Java中使用Kafka客户端需要引入依赖：

```xml
<dependency>
    <groupId>org.apache.kafka</groupId>
    <artifactId>kafka-clients</artifactId>
    <version>2.5.0</version>
</dependency>
```

* ### 创建生产者

```java
public static void main(String[] args) throws Exception {
    //1、设置生产者属性
    Properties properties = new Properties();
    //服务地址
    properties.put("bootstrap.servers","192.168.154.130:9092");
    //序列化器
    properties.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
    properties.put("value.serializer","org.apache.kafka.common.serialization.StringSerializer");

    //2、创建生产者对象
    KafkaProducer kafkaProducer = new KafkaProducer(properties);

    //3、创建Student对象，并转换为JSON字符串
    Student student = new Student("张三", 50, 80);
    String json = JSON.toJSONString(student);

    try{
        //4、将JSON字符串发送到名为mykafka的Topic中，指定key为1
        ProducerRecord<String, String> producerRecord = new ProducerRecord("mykafka","1",json); 
        Future future = kafkaProducer.send(producerRecord);
        //5、调用get()方法，同步发送消息，主程序会等待Kafka返回结果
        future.get();
    }catch(Exception e){
        e.printStackTrace();
    }
}
```

　　生产者还有一些其它属性可以设置，本文不再赘述。

　　也可以异步发送消息，发送消息时不需要等待上一条消息返回，提高了效率。为了在异步发送的时候能够对异常情况进行处理，可以传入一个回调函数：

```java
//不调用get()方法，异步发送消息，并传入回调函数处理异常
Future future = kafkaProducer.send(producerRecord,((recordMetadata, e) -> {
    e.printStackTrace();
}));
```

## 三、消费者

* ### 创建消费者

```java
public static void main(String[] args) {
    //设置消费者属性
    Properties properties = new Properties();
    //服务地址
    properties.put("bootstrap.servers","192.168.154.130:9092");
    //反序列化器
    properties.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
    properties.put("value.deserializer","org.apache.kafka.common.serialization.StringDeserializer");
    //消费组id
    properties.put("group.id","group1");

    //2、创建消费者对象
    KafkaConsumer<String,String> kafkaConsumer = new KafkaConsumer<>(properties);
    
    //3、消费者订阅Topic列表
    ArrayList<String> list = new ArrayList<>();
    list.add("mykafka");
    kafkaConsumer.subscribe(list);

    //4、通过循环向服务器发送请求
    while (true){
        //poll()方法返回一个记录列表，每条记录都包含了Topic、Partition、Offset、key、value等
        ConsumerRecords<String, String> records = kafkaConsumer.poll(100); //100表示在100ms内会一直等待服务器返回数据
        for(ConsumerRecord<String,String> record:records){
            String topic = record.topic();
            int partition = record.partition();
            long offset = record.offset();
            String key = record.key();
            String value = record.value();
            Student student = JSON.parseObject(value, Student.class);
        }
    }
}
```

　　消费者还有一些其它属性可以设置，本文不再赘述。



本文参考：

1、《Kafka权威指南》